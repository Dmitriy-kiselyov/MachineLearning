{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы восстановления регрессии\n",
    "\n",
    "Задачу обучения по прецедентам при $Y=\\mathbb{R}$ принято называть задачей восстановления регрессии. Задано пространство объектов X и множество возможных ответов Y. Существует неизвестная целевая зависимость $y^*:X\\rightarrow Y$ , значения которой известны только на объектах обучающей выборки $X^\\ell = (x_i, y_i)_{i-1}^\\ell, y_i = y^* (x_i)$. Требуется построить алгоритм, который в данной задаче принято называть \"функцией регрессии\" $a: X^* \\rightarrow Y$ , аппроксимирующий целевую зависимость $y^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Линейная регрессия\n",
    " \n",
    "Для начала настроим окружение jupiter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И установим внешние зависимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающую выборку возьмём из `sklearn` – `datasets.diabetes`. Выборка специально подготовлена для демонстрации возможностей линейной регрессии, содержит 442 объекта по 10 признаков.\n",
    "\n",
    "**Задача** этого примера реализовать линейную регрессию и технику *svd (singular value decomposition)*, сравнить их между собой и сравнить с реализацией линейной регрессии библиотекой `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающие и тестовые выборки диабетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()  # 442 Объекта, 10 признаков\n",
    "\n",
    "def prepare_dataset(size, features):\n",
    "    diabetes_X = diabetes.data[:(size * 2), :features]\n",
    "    diabetes_y = diabetes.target[:(size * 2)]\n",
    "\n",
    "    diabetes_X_train = diabetes_X[:size]\n",
    "    diabetes_X_test = diabetes_X[-size:]\n",
    "\n",
    "    diabetes_y_train = diabetes_y[:size]\n",
    "    diabetes_y_test = diabetes_y[-size:]\n",
    "\n",
    "    return diabetes_X_train, diabetes_y_train,\\\n",
    "           diabetes_X_test, diabetes_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейную регрессию оформем в виде класса с методами `fit` для обучения алгоритма, методом `predict` для ответов по тестовой выборке и геттером `coeffs` для получения коэффициентов (весов) регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение нормальной системы\n",
    "\n",
    "*Линейной моделью регресси называется уравнение вида* – $\\phi(x, \\alpha)=\\sum_{i=1}^n \\alpha_j \\cdot f_j(x)$. $F$ – матрица признаков. Задача – вычилить параметры алгоритма ($\\alpha$).\n",
    "\n",
    "$\\alpha^* = (F^TF)^{-1}F^Ty = F^+y$\n",
    "\n",
    "Матрица $F^+$ называется *псевдообратной*. Решив это уравнение, получим параметры алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение через SVD\n",
    "\n",
    "Принцип *SVD* заключается в том, чтобы разложить $F$ на 3 матрицы:\n",
    "\n",
    "$F = VDU^T$\n",
    "\n",
    "$D$ – диагональная матрица собственных значений $F^TF$\n",
    "\n",
    "$V$ – ортогональная матрица $l \\times n$\n",
    "\n",
    "$U$ – ортогональная матрица $n \\times n$\n",
    "\n",
    "Проделав сингулярное разбиение, можно вычислить параметры алгоритма:\n",
    "\n",
    "$a^* = F^+y = UD^{-1}V^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных\n",
    "\n",
    "Линейная регрессия даёт очень плохие результаты, если данные перед использованием не нормировать.\n",
    "\n",
    "Для хороших результатов, нужно центрировать каждый признак, а также ответы по среднему значению по оси координат. От этого центрирования меняются коэффициенты уравнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм\n",
    "\n",
    "Код линейной регрессии, *svd* и нормализации данных будет находится внутри класса `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, svd=False, preprocess=True):\n",
    "        self.__svd = svd\n",
    "        self.__has_preprocess = preprocess\n",
    "        self.__intercept = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.has_preprocess:\n",
    "            X, y, X_offset, y_offset = self.__preprocess(X, y)\n",
    "\n",
    "        pseudo_inverse = self.__pseudo_svd(X) if self.is_svd else self.__pseudo_linear(X)\n",
    "        self.__w = np.dot(pseudo_inverse, y)\n",
    "\n",
    "        if self.has_preprocess:\n",
    "            self.__set_intercept(X_offset, y_offset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.__w) + self.__intercept\n",
    "\n",
    "    @property\n",
    "    def coeffs(self):\n",
    "        return self.__w\n",
    "\n",
    "    @property\n",
    "    def is_svd(self):\n",
    "        return self.__svd\n",
    "\n",
    "    @property\n",
    "    def has_preprocess(self):\n",
    "        return self.__has_preprocess\n",
    "\n",
    "    def __pseudo_linear(self, F):\n",
    "        F_transpose = np.transpose(F)\n",
    "\n",
    "        return np.dot(np.linalg.inv(np.dot(F_transpose, F)), F_transpose)\n",
    "\n",
    "    def __pseudo_svd(self, F):\n",
    "        P, D, Q = np.linalg.svd(F, full_matrices=False)\n",
    "        V = P\n",
    "        U = Q\n",
    "        D = np.diag(D)\n",
    "\n",
    "        return np.dot(np.dot(U, np.linalg.inv(D)), np.transpose(V))\n",
    "\n",
    "    def __set_intercept(self, X_offset, y_offset):\n",
    "        self.__intercept = y_offset - np.dot(X_offset, self.coeffs)\n",
    "\n",
    "    def __preprocess(self, X, y):\n",
    "        X_offset = np.average(X, axis=0)\n",
    "        X -= X_offset\n",
    "\n",
    "        y_offset = np.average(y, axis=0)\n",
    "        y = y - y_offset\n",
    "\n",
    "        return X, y, X_offset, y_offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения 3х алгоритмов сделаем вспомогательную функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(size, features, preprocess):\n",
    "    diabetes_X_train, diabetes_y_train, diabetes_X_test, diabetes_y_test = prepare_dataset(size, features)\n",
    "\n",
    "    sk_y_est = sklearn_predict(diabetes_X_train, diabetes_y_train, diabetes_X_test, preprocess)\n",
    "    print(\"Средняя квадратичная ошика: %.2f\"\n",
    "          % mean_squared_error(diabetes_y_test, sk_y_est))\n",
    "\n",
    "    linear_y_est = linear_predict(diabetes_X_train, diabetes_y_train, diabetes_X_test, preprocess)\n",
    "    print(\"Средняя квадратичная ошика: %.2f\"\n",
    "          % mean_squared_error(diabetes_y_test, linear_y_est))\n",
    "\n",
    "    svd_y_est = svd_predict(diabetes_X_train, diabetes_y_train, diabetes_X_test, preprocess)\n",
    "    print(\"Средняя квадратичная ошика: %.2f\"\n",
    "          % mean_squared_error(diabetes_y_test, svd_y_est))\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    print('Правильно: ', diabetes_y_test)\n",
    "    print('Skykit:    ', np.floor(sk_y_est))\n",
    "    print('Linear:    ', np.floor(linear_y_est))\n",
    "    print('SVD:       ', np.floor(svd_y_est))\n",
    "\n",
    "    \n",
    "def sklearn_predict(X_train, y, X_test, preprocess):\n",
    "    regr = linear_model.LinearRegression(fit_intercept=preprocess)\n",
    "    regr.fit(X_train, y)\n",
    "\n",
    "    print('SKYKIT: ', np.round(regr.coef_, 2))\n",
    "\n",
    "    return regr.predict(X_test)\n",
    "\n",
    "\n",
    "def linear_predict(X_train, y, X_test, preprocess):\n",
    "    regr = LinearRegression(preprocess=preprocess)\n",
    "    regr.fit(X_train, y)\n",
    "\n",
    "    print('LINEAR: ', np.round(regr.coeffs, 2))\n",
    "\n",
    "    return regr.predict(X_test)\n",
    "\n",
    "\n",
    "def svd_predict(X_train, y, X_test, preprocess):\n",
    "    regr = LinearRegression(svd=True, preprocess=preprocess)\n",
    "    regr.fit(X_train, y)\n",
    "\n",
    "    print('SVD: ', np.round(regr.coeffs, 2))\n",
    "\n",
    "    return regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тесты\n",
    "\n",
    "Запустим обучение на 50 объектах на 2х признаках без нормализации данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKYKIT:  [-515.25  333.14]\n",
      "Средняя квадратичная ошика: 20454.51\n",
      "LINEAR:  [-515.25  333.14]\n",
      "Средняя квадратичная ошика: 20454.51\n",
      "SVD:  [-515.25  333.14]\n",
      "Средняя квадратичная ошика: 20454.51\n",
      "---------------------------------------------------------\n",
      "Правильно:  [155. 225.  59. 104. 182. 128.  52.  37. 170. 170.  61. 144.  52. 128.\n",
      "  71. 163. 150.  97. 160. 178.  48. 270. 202. 111.  85.  42. 170. 200.\n",
      " 252. 113. 143.  51.  52. 210.  65. 141.  55. 134.  42. 111.  98. 164.\n",
      "  48.  96.  90. 162. 150. 279.  92.  83.]\n",
      "Skykit:     [-33. -14.  12. -11.  10.   6.   6.  -1. -37. -16.  21.  38.  30.   2.\n",
      " -18.  40.  21.  -5.  -3. -24. -14. -14. -16.  10.  10.  21.  32.  34.\n",
      " -18.  38. -52.  10.  -7.   4. -16. -39.  53. -39.  44.   8. -22. -39.\n",
      "  -5.  10.  25.  21. -13.  -1.  15. -14.]\n",
      "Linear:     [-33. -14.  12. -11.  10.   6.   6.  -1. -37. -16.  21.  38.  30.   2.\n",
      " -18.  40.  21.  -5.  -3. -24. -14. -14. -16.  10.  10.  21.  32.  34.\n",
      " -18.  38. -52.  10.  -7.   4. -16. -39.  53. -39.  44.   8. -22. -39.\n",
      "  -5.  10.  25.  21. -13.  -1.  15. -14.]\n",
      "SVD:        [-33. -14.  12. -11.  10.   6.   6.  -1. -37. -16.  21.  38.  30.   2.\n",
      " -18.  40.  21.  -5.  -3. -24. -14. -14. -16.  10.  10.  21.  32.  34.\n",
      " -18.  38. -52.  10.  -7.   4. -16. -39.  53. -39.  44.   8. -22. -39.\n",
      "  -5.  10.  25.  21. -13.  -1.  15. -14.]\n"
     ]
    }
   ],
   "source": [
    "compare(50, 2, preprocess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы имеют одинаковые веса и одинаковые значения `y`, но при этом дают почти случайный результат.\n",
    "\n",
    "Включим нормализацию данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKYKIT:  [124.45  70.41]\n",
      "Средняя квадратичная ошика: 4128.82\n",
      "LINEAR:  [124.45  70.41]\n",
      "Средняя квадратичная ошика: 4128.82\n",
      "SVD:  [124.45  70.41]\n",
      "Средняя квадратичная ошика: 4081.00\n",
      "---------------------------------------------------------\n",
      "Правильно:  [155. 225.  59. 104. 182. 128.  52.  37. 170. 170.  61. 144.  52. 128.\n",
      "  71. 163. 150.  97. 160. 178.  48. 270. 202. 111.  85.  42. 170. 200.\n",
      " 252. 113. 143.  51.  52. 210.  65. 141.  55. 134.  42. 111.  98. 164.\n",
      "  48.  96.  90. 162. 150. 279.  92.  83.]\n",
      "Skykit:     [144. 154. 133. 139. 134. 135. 135. 137. 145. 155. 131. 142. 143. 136.\n",
      " 155. 141. 146. 152. 151. 142. 140. 140. 155. 148. 148. 146. 143. 128.\n",
      " 141. 127. 149. 148. 138. 135. 140. 146. 138. 146. 140. 134. 142. 146.\n",
      " 138. 134. 130. 131. 154. 137. 147. 140.]\n",
      "Linear:     [144. 154. 133. 139. 134. 135. 135. 137. 145. 155. 131. 142. 143. 136.\n",
      " 155. 141. 146. 152. 151. 142. 140. 140. 155. 148. 148. 146. 143. 128.\n",
      " 141. 127. 149. 148. 138. 135. 140. 146. 138. 146. 140. 134. 142. 146.\n",
      " 138. 134. 130. 131. 154. 137. 147. 140.]\n",
      "SVD:        [143. 153. 132. 137. 132. 133. 133. 135. 144. 153. 130. 140. 142. 134.\n",
      " 154. 140. 144. 150. 150. 141. 138. 138. 153. 147. 147. 144. 141. 127.\n",
      " 139. 126. 147. 147. 137. 134. 139. 144. 136. 144. 139. 133. 140. 144.\n",
      " 136. 132. 129. 130. 152. 135. 146. 138.]\n"
     ]
    }
   ],
   "source": [
    "compare(50, 2, preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация улучшила ответ в несколько раз и сделала `y` похожими на настоящий ответ. Однако, значения *svd* немного отличаются. Увеличим число признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKYKIT:  [ -72.3  -209.53 1033.39]\n",
      "Средняя квадратичная ошика: 3609.81\n",
      "LINEAR:  [ -72.3  -209.53 1033.39]\n",
      "Средняя квадратичная ошика: 3609.81\n",
      "SVD:  [932.88 495.77  30.99]\n",
      "Средняя квадратичная ошика: 5924.98\n",
      "---------------------------------------------------------\n",
      "Правильно:  [155. 225.  59. 104. 182. 128.  52.  37. 170. 170.  61. 144.  52. 128.\n",
      "  71. 163. 150.  97. 160. 178.  48. 270. 202. 111.  85.  42. 170. 200.\n",
      " 252. 113. 143.  51.  52. 210.  65. 141.  55. 134.  42. 111.  98. 164.\n",
      "  48.  96.  90. 162. 150. 279.  92.  83.]\n",
      "Skykit:     [146. 149. 150. 141. 186. 108. 202.  93.  87. 105. 157. 144. 131. 120.\n",
      " 105. 114. 118. 118. 103. 107.  84. 191. 128. 115. 138. 105. 168. 126.\n",
      "  96. 125. 164. 112. 121. 169. 115. 227.  64. 147.  98. 110. 129. 207.\n",
      " 162.  93. 144. 102. 143. 250. 131.  90.]\n",
      "Linear:     [146. 149. 150. 141. 186. 108. 202.  93.  87. 105. 157. 144. 131. 120.\n",
      " 105. 114. 118. 118. 103. 107.  84. 191. 128. 115. 138. 105. 168. 126.\n",
      "  96. 125. 164. 112. 121. 169. 115. 227.  64. 147.  98. 110. 129. 207.\n",
      " 162.  93. 144. 102. 143. 250. 131.  90.]\n",
      "SVD:        [151. 223.  70. 111.  75.  79.  82.  92. 157. 225.  53. 128. 141.  86.\n",
      " 229. 124. 158. 205. 201. 133. 116. 119. 226. 178. 179. 157. 139.  29.\n",
      " 123.  22. 186. 178. 103.  84. 120. 164.  98. 162. 116.  76. 131. 163.\n",
      " 101.  72.  46.  52. 220.  97. 168. 116.]\n"
     ]
    }
   ],
   "source": [
    "compare(50, 3, preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*svd* начал сильно отставать. Чем больше будет количество признаков, тем сильнее он будет отличаться от ближайших алгоритмов. Отставание не зависит от кличества объектов выборки, но зависит от нормализации.\n",
    "\n",
    "Видимо, обычной нормализации по оси координат недостаточно для *svd*, чтобы показывать оптимальные результаты для `features > 2`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
