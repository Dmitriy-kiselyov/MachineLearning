{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы восстановления регрессии\n",
    "\n",
    "Задачу обучения по прецедентам при $Y=\\mathbb{R}$ принято называть задачей восстановления регрессии. Задано пространство объектов X и множество возможных ответов Y. Существует неизвестная целевая зависимость $y^*:X\\rightarrow Y$ , значения которой известны только на объектах обучающей выборки $X^\\ell = (x_i, y_i)_{i-1}^\\ell, y_i = y^* (x_i)$. Требуется построить алгоритм, который в данной задаче принято называть \"функцией регрессии\" $a: X^* \\rightarrow Y$ , аппроксимирующий целевую зависимость $y^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Линейная регрессия\n",
    " \n",
    "Для начала настроим окружение jupiter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И установим внешние зависимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающую выборку возьмём из `sklearn` – `datasets.diabetes`. Выборка специально подготовлена для демонстрации возможностей линейной регрессии, содержит 442 объекта по 10 признаков.\n",
    "\n",
    "**Задача** этого примера реализовать линейную регрессию и технику *svd (singular value decomposition)*, сравнить их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающие и тестовые выборки диабетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()  # 442 Объекта, 10 признаков\n",
    "\n",
    "def prepare_dataset(size, features):\n",
    "    diabetes_X = diabetes.data[:(size * 2), :features]\n",
    "    diabetes_y = diabetes.target[:(size * 2)]\n",
    "\n",
    "    diabetes_X_train = diabetes_X[:size]\n",
    "    diabetes_X_test = diabetes_X[-size:]\n",
    "\n",
    "    diabetes_y_train = diabetes_y[:size]\n",
    "    diabetes_y_test = diabetes_y[-size:]\n",
    "\n",
    "    return diabetes_X_train, diabetes_y_train, diabetes_X_test, diabetes_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейную регрессию оформем в виде класса с методами `fit` для обучения алгоритма, методом `predict` для ответов по тестовой выборке и геттером `coeffs` для получения коэффициентов (весов) регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение нормальной системы\n",
    "\n",
    "*Линейной моделью регресси называется уравнение вида* – $\\phi(x, \\alpha)=\\sum_{i=1}^n \\alpha_j \\cdot f_j(x)$. $F$ – матрица признаков. Задача – вычилить параметры алгоритма ($\\alpha$).\n",
    "\n",
    "$\\alpha^* = (F^TF)^{-1}F^Ty = F^+y$\n",
    "\n",
    "Матрица $F^+$ называется *псевдообратной*. Решив это уравнение, получим параметры алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение через SVD\n",
    "\n",
    "Принцип *SVD* заключается в том, чтобы разложить $F$ на 3 матрицы:\n",
    "\n",
    "$F = VDU^T$\n",
    "\n",
    "$D$ – диагональная матрица собственных значений $F^TF$\n",
    "\n",
    "$V$ – ортогональная матрица $l \\times n$\n",
    "\n",
    "$U$ – ортогональная матрица $n \\times n$\n",
    "\n",
    "Проделав сингулярное разбиение, можно вычислить параметры алгоритма:\n",
    "\n",
    "$a^* = F^+y = UD^{-1}V^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод *сингулярного разложения* обладает положительной особенностью. Если матрица признаков слишком большая, то матрицу можно сократить до $r$ признаков. Это не только уменьшит скорость работы, но и количество потребляемой памяти. Для этого нужно после сингулярного разложения оставить $r$ колонок матрицы $V$, $r$ колонок и строк матриц $D$ и $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных\n",
    "\n",
    "Линейная регрессия даёт очень плохие результаты, если данные перед использованием не нормировать.\n",
    "\n",
    "Для хороших результатов, нужно центрировать каждый признак, а также ответы по среднему значению по оси координат. От этого центрирования меняются коэффициенты уравнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм\n",
    "\n",
    "Код линейной регрессии и нормализации данных будет находится внутри класса `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, preprocess=True):\n",
    "        self.__has_preprocess = preprocess\n",
    "        self.__intercept = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.has_preprocess:\n",
    "            X, y, X_offset, y_offset = self.__preprocess(X, y)\n",
    "\n",
    "        F = X\n",
    "        F_transpose = np.transpose(F)\n",
    "\n",
    "        pseudo_inverse = np.dot(np.linalg.inv(np.dot(F_transpose, F)), F_transpose)\n",
    "        self.__w = np.dot(pseudo_inverse, y)\n",
    "\n",
    "        if self.has_preprocess:\n",
    "            self.__set_intercept(X_offset, y_offset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.__w) + self.__intercept\n",
    "\n",
    "    @property\n",
    "    def coeffs(self):\n",
    "        return self.__w\n",
    "\n",
    "    @property\n",
    "    def has_preprocess(self):\n",
    "        return self.__has_preprocess\n",
    "\n",
    "    def __pseudo_linear(self, F):\n",
    "        F_transpose = np.transpose(F)\n",
    "\n",
    "        return np.dot(np.linalg.inv(np.dot(F_transpose, F)), F_transpose)\n",
    "\n",
    "    def __set_intercept(self, X_offset, y_offset):\n",
    "        self.__intercept = y_offset - np.dot(X_offset, self.coeffs)\n",
    "\n",
    "    def __preprocess(self, X, y):\n",
    "        X_offset = np.average(X, axis=0)\n",
    "        X = X - X_offset\n",
    "\n",
    "        y_offset = np.average(y, axis=0)\n",
    "        y = y - y_offset\n",
    "\n",
    "        return X, y, X_offset, y_offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код **svd** будет находится в классе `SVD`. У него, кроме параметра нормализации, будет ещё один параметр `cut` – нужно ли обрезать количество признаков. Обрезка будет проиходить по 2м признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, preprocess=True, cut=True):\n",
    "        self.__has_preprocess = preprocess\n",
    "        self.__cut = cut\n",
    "        self.__intercept = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.has_preprocess:\n",
    "            X, y, X_offset, y_offset = self.__preprocess(X, y)\n",
    "\n",
    "        V, D, U = self.__svd(X)\n",
    "\n",
    "        pseudo_inverse = np.dot(np.dot(U, np.linalg.inv(D)), np.transpose(V))\n",
    "        self.__w = np.dot(pseudo_inverse, y)\n",
    "\n",
    "        if self.has_preprocess:\n",
    "            self.__set_intercept(X_offset, y_offset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.uses_cut:\n",
    "            X = X[:, :2]\n",
    "\n",
    "        return np.dot(X, self.__w) + self.__intercept\n",
    "\n",
    "    @property\n",
    "    def coeffs(self):\n",
    "        return self.__w\n",
    "\n",
    "    @property\n",
    "    def has_preprocess(self):\n",
    "        return self.__has_preprocess\n",
    "\n",
    "    @property\n",
    "    def uses_cut(self):\n",
    "        return self.__cut\n",
    "\n",
    "    def __set_intercept(self, X_offset, y_offset):\n",
    "        self.__intercept = y_offset - np.dot(X_offset, self.coeffs)\n",
    "\n",
    "    def __preprocess(self, X, y):\n",
    "        if self.uses_cut:\n",
    "            X = X[:, :2]\n",
    "\n",
    "        X_offset = np.average(X, axis=0)\n",
    "        X = X - X_offset\n",
    "\n",
    "        y_offset = np.average(y, axis=0)\n",
    "        y = y - y_offset\n",
    "\n",
    "        return X, y, X_offset, y_offset\n",
    "\n",
    "    def __svd(self, X):\n",
    "        V, D, U = np.linalg.svd(X, full_matrices=False)\n",
    "        U = np.transpose(U)\n",
    "        D = np.diag(D)\n",
    "\n",
    "        if self.uses_cut:\n",
    "            V = V[:, :2]\n",
    "            D = D[:2, :2]\n",
    "            U = U[:2, :2]\n",
    "\n",
    "        return V, D, U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения алгоритмов сделаем вспомогательную функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algo(algo, size, features, preprocess, cut=False):\n",
    "    print(algo, ': features =', features, '; preprocess =', preprocess)\n",
    "    if cut:\n",
    "        print('Using cut')\n",
    "\n",
    "    diabetes_X_train, diabetes_y_train, diabetes_X_test, diabetes_y_test = prepare_dataset(size, features)\n",
    "\n",
    "    y_est = predict(algo, diabetes_X_train, diabetes_y_train, diabetes_X_test, preprocess, cut)\n",
    "    print(\"Средняя квадратичная ошика: %.2f\"\n",
    "          % mean_squared_error(diabetes_y_test, y_est))\n",
    "    print('-----------------------------------------------------')\n",
    "    \n",
    "\n",
    "def predict(algo, X_train, y, X_test, preprocess, cut):\n",
    "    regr = None\n",
    "    if algo == 'linear':\n",
    "        regr = LinearRegression(preprocess=preprocess)\n",
    "    elif algo == 'svd':\n",
    "        regr = SVD(preprocess=preprocess, cut=cut)\n",
    "\n",
    "    regr.fit(X_train, y)\n",
    "\n",
    "    print('Coeffs: ', np.round(regr.coeffs, 2))\n",
    "\n",
    "    return regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тесты\n",
    "\n",
    "Запустим обучение на 50 объектах на 7х признаках без нормализации данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear : features = 7 ; preprocess = False\n",
      "Coeffs:  [ -694.68   721.62  1102.04   -27.68   549.71 -1784.24   116.97]\n",
      "Средняя квадратичная ошика: 25019.27\n",
      "-----------------------------------------------------\n",
      "svd : features = 7 ; preprocess = False\n",
      "Coeffs:  [ -694.68   721.62  1102.04   -27.68   549.71 -1784.24   116.97]\n",
      "Средняя квадратичная ошика: 25019.27\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_algo('linear', size=50, features=7, preprocess=False)\n",
    "test_algo('svd', size=50, features=7, preprocess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы имеют одинаковые веса и одинаковые ошибки, но при этом дают очень плохой результат.\n",
    "\n",
    "Включим обрезку до 2х признаков в **svd**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear : features = 7 ; preprocess = False\n",
      "Coeffs:  [ -694.68   721.62  1102.04   -27.68   549.71 -1784.24   116.97]\n",
      "Средняя квадратичная ошика: 25019.27\n",
      "-----------------------------------------------------\n",
      "svd : features = 7 ; preprocess = False\n",
      "Using cut\n",
      "Coeffs:  [-347.7    31.06]\n",
      "Средняя квадратичная ошика: 19476.60\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_algo('linear', size=50, features=7, preprocess=False)\n",
    "test_algo('svd', size=50, features=7, preprocess=False, cut=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрезка параметров не только ускорила время работы и сократила память, но и улучшила показатели по сравнению с 7ю параметрами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако показатели алгоритма плохие, так как данные не отцентрованы. Отцентрируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear : features = 7 ; preprocess = True\n",
      "Coeffs:  [  -14.14  -399.25   622.59   348.05  1593.21 -1673.51  -821.45]\n",
      "Средняя квадратичная ошика: 2855.08\n",
      "-----------------------------------------------------\n",
      "svd : features = 7 ; preprocess = True\n",
      "Coeffs:  [  -14.14  -399.25   622.59   348.05  1593.21 -1673.51  -821.45]\n",
      "Средняя квадратичная ошика: 2855.08\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_algo('linear', size=50, features=7, preprocess=True)\n",
    "test_algo('svd', size=50, features=7, preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация улучшила ответ в несколько раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, если включить с нормализацией данных обрезку параметров для **svd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear : features = 7 ; preprocess = True\n",
      "Coeffs:  [  -14.14  -399.25   622.59   348.05  1593.21 -1673.51  -821.45]\n",
      "Средняя квадратичная ошика: 2855.08\n",
      "-----------------------------------------------------\n",
      "svd : features = 7 ; preprocess = True\n",
      "Using cut\n",
      "Coeffs:  [124.45  70.41]\n",
      "Средняя квадратичная ошика: 4128.82\n",
      "-----------------------------------------------------\n",
      "linear : features = 2 ; preprocess = True\n",
      "Coeffs:  [124.45  70.41]\n",
      "Средняя квадратичная ошика: 4128.82\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_algo('linear', size=50, features=7, preprocess=True)\n",
    "test_algo('svd', size=50, features=7, preprocess=True, cut=True)\n",
    "test_algo('linear', size=50, features=2, preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ответ **svd** будет хуже и не будет отличаться от ответа линейной регрессии для 2х признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге, оба метода отличаются лишь способом разрешения матричного уравнения, но оба способа не отличаются друг от друга по результативности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
